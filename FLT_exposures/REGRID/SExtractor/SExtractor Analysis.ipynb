{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from glob import glob\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD > 5 times MAG error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classes and definitions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "### Read from additioned FLT frames ###\n",
    "#######################################\n",
    "\n",
    "class read_sexcats():\n",
    "    def __init__(self):\n",
    "        #phot_df = self.join(1)\n",
    "        self.phot_df = self.join()#2, phot_df)\n",
    "        #phot_df = self.return_func(phot_df)\n",
    "        \n",
    "    def join(self, phot_df=None):\n",
    "        items = np.sort(glob('../Add_Regrid/*add_regrid.fits'))\n",
    "        #np.sort([w.split('_flt')[0] for w in glob('./wfc'+str(wfc)+'/*rate*regrid.fits')])\n",
    "        for iterator in range(len(items)):\n",
    "            item = items[iterator]\n",
    "            hdul = fits.open(item)\n",
    "            expstart = hdul[1].header['EXPSTART']\n",
    "            EXPTIME  = hdul[1].header['EXPTIME']\n",
    "            filter_  = hdul[1].header['FILTER']\n",
    "            sexcat_file = item.replace('add_regrid', 'phot')\n",
    "            sexcat = Table.read(sexcat_file, format=\"fits\", hdu='LDAC_OBJECTS')#.to_pandas()\n",
    "            sexcat = self.unpack_apers(sexcat)\n",
    "            sexcat.remove_columns(['MAG_APER', 'MAGERR_APER', 'FLUX_APER', 'FLUXERR_APER'])    \n",
    "            sexcat = sexcat.to_pandas()\n",
    "\n",
    "            sexcat = sexcat.rename(columns={'NUMBER':'SExID'})\n",
    "            sexcat = sexcat.rename(columns={'VECTOR_ASSOC':'AssocID'})\n",
    "            \n",
    "            sexcat['AssocID'] = sexcat['AssocID'].astype(int)\n",
    "            sexcat = sexcat[sexcat.AssocID!=0]\n",
    "\n",
    "            sexcat['T_Start'] = expstart\n",
    "            sexcat['Exptime'] = EXPTIME\n",
    "            sexcat['Exp_Length'] = ('deep' if EXPTIME > 31 else 'short')\n",
    "            sexcat['Filter']     = filter_\n",
    "            #sexcat['WhichWFC']   = wfc\n",
    "            sexcat = self.clean(sexcat)\n",
    "            #sexcat = sexcat.set_index('ID')\n",
    "            try:\n",
    "                phot_df = pd.concat((phot_df,sexcat), axis=0)\n",
    "            except:\n",
    "                phot_df = sexcat\n",
    "        return phot_df\n",
    "        \n",
    "    def return_func(self):\n",
    "        print('Done. Returning photometry dataframe')\n",
    "        return self.phot_df.set_index(['AssocID', 'Filter', 'T_Start', 'Exp_Length']).sort_index()\n",
    "    \n",
    "    def clean(self, sexcat):\n",
    "        \"\"\"I take all rules from the HCV catalogue\"\"\"\n",
    "        sexcat = sexcat[(sexcat.MAG_APER2<80)&(sexcat.MAG_AUTO<80)]\n",
    "        sexcat = sexcat[sexcat.MAG_APER2<31.0]\n",
    "        sexcat = sexcat[sexcat.MAG_AUTO<35.0]\n",
    "        sexcat = sexcat[sexcat.FLAGS<=7]\n",
    "        sexcat = sexcat[sexcat.MAGERR_APER2<0.2]\n",
    "        return sexcat\n",
    "    \n",
    "    def unpack_apers(self, sexcat):\n",
    "        \"\"\"Unpacking the stacked lists\n",
    "           NOTES:\n",
    "           APER1 and APER2 refer to Whitmore et al 2016 (2.5 and 7.5 pixels diameter)\n",
    "           APER3 refers to our own aperture, which is 6 pixels in diameter\n",
    "           \"\"\"\n",
    "        sexcat['FLUX_APER1'] = [w[0] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUX_APER3'] = [w[1] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUX_APER2'] = [w[2] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUXERR_APER1'] = [w[0] for w in sexcat['FLUXERR_APER']]\n",
    "        sexcat['FLUXERR_APER3'] = [w[1] for w in sexcat['FLUXERR_APER']]\n",
    "        sexcat['FLUXERR_APER2'] = [w[2] for w in sexcat['FLUXERR_APER']]\n",
    "\n",
    "        sexcat['MAG_APER1'] = [w[0] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAG_APER3'] = [w[1] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAG_APER2'] = [w[2] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAGERR_APER1'] = [w[0] for w in sexcat['MAGERR_APER']]\n",
    "        sexcat['MAGERR_APER3'] = [w[1] for w in sexcat['MAGERR_APER']]\n",
    "        sexcat['MAGERR_APER2'] = [w[2] for w in sexcat['MAGERR_APER']]\n",
    "        return sexcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "### Read from single regridded FLT frames ###\n",
    "#############################################\n",
    "class read_sexcats():\n",
    "    def __init__(self):\n",
    "        phot_df = self.join(1)\n",
    "        self.phot_df = self.join(2, phot_df)\n",
    "        #phot_df = self.return_func(phot_df)\n",
    "        \n",
    "    def join(self, wfc, phot_df=None):\n",
    "        items = np.sort([w.split('_flt')[0] for w in glob('./wfc'+str(wfc)+'/*rate*regrid.fits')])\n",
    "        for iterator in range(len(items)):\n",
    "            item = items[iterator]\n",
    "            hdul = fits.open(glob(item+'*regrid*')[0])\n",
    "            expstart = hdul[0].header['EXPSTART']\n",
    "            EXPTIME  = hdul[0].header['EXPTIME']\n",
    "            filter_  = hdul[0].header['FILTER']\n",
    "            sexcat = Table.read(glob(item+'*phot*')[0], format=\"fits\", hdu='LDAC_OBJECTS')#.to_pandas()\n",
    "            sexcat = self.unpack_apers(sexcat)\n",
    "            sexcat.remove_columns(['MAG_APER', 'MAGERR_APER', 'FLUX_APER', 'FLUXERR_APER'])    \n",
    "            sexcat = sexcat.to_pandas()\n",
    "\n",
    "            sexcat = sexcat.rename(columns={'NUMBER':'SExID'})\n",
    "            sexcat = sexcat.rename(columns={'VECTOR_ASSOC':'AssocID'})\n",
    "            \n",
    "            sexcat['AssocID'] = sexcat['AssocID'].astype(int)\n",
    "            sexcat = sexcat[sexcat.AssocID!=0]\n",
    "            if wfc==2: \n",
    "                sexcat.SExID += phot_df[phot_df.WhichWFC==1].SExID.max()\n",
    "            #sexcat = sexcat.rename(columns={'VECTOR_ASSOC':'ID'})\n",
    "            #sexcat['ID'] = sexcat['ID'].astype(int)\n",
    "\n",
    "            sexcat['T_Start'] = expstart\n",
    "            sexcat['Exptime'] = EXPTIME\n",
    "            sexcat['Exp_Length'] = ('deep' if EXPTIME > 31 else 'short')\n",
    "            sexcat['Filter']     = filter_\n",
    "            sexcat['WhichWFC']   = wfc\n",
    "            sexcat = self.clean(sexcat)\n",
    "            #sexcat = sexcat.set_index('ID')\n",
    "            try:\n",
    "                phot_df = pd.concat((phot_df,sexcat), axis=0)\n",
    "            except:\n",
    "                phot_df = sexcat\n",
    "        return phot_df\n",
    "        \n",
    "    def return_func(self):\n",
    "        print('Done. Returning photometry dataframe')\n",
    "        return self.phot_df.set_index(['AssocID', 'Filter', 'T_Start']).sort_index()\n",
    "    \n",
    "    def clean(self, sexcat):\n",
    "        \"\"\"I take all rules from the HCV catalogue\"\"\"\n",
    "        sexcat = sexcat[(sexcat.MAG_APER2<80)&(sexcat.MAG_AUTO<80)]\n",
    "        sexcat = sexcat[sexcat.MAG_APER2<31.0]\n",
    "        sexcat = sexcat[sexcat.MAG_AUTO<35.0]\n",
    "        sexcat = sexcat[sexcat.FLAGS<=7]\n",
    "        sexcat = sexcat[sexcat.MAGERR_APER2<0.2]\n",
    "        return sexcat\n",
    "    \n",
    "    def unpack_apers(self, sexcat):\n",
    "        \"\"\"Unpacking the stacked lists\n",
    "           NOTES:\n",
    "           APER1 and APER2 refer to Whitmore et al 2016 (2.5 and 7.5 pixels diameter)\n",
    "           APER3 refers to our own aperture, which is 6 pixels in diameter\n",
    "           \"\"\"\n",
    "        sexcat['FLUX_APER1'] = [w[0] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUX_APER3'] = [w[1] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUX_APER2'] = [w[2] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUXERR_APER1'] = [w[0] for w in sexcat['FLUXERR_APER']]\n",
    "        sexcat['FLUXERR_APER3'] = [w[1] for w in sexcat['FLUXERR_APER']]\n",
    "        sexcat['FLUXERR_APER2'] = [w[2] for w in sexcat['FLUXERR_APER']]\n",
    "\n",
    "        sexcat['MAG_APER1'] = [w[0] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAG_APER3'] = [w[1] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAG_APER2'] = [w[2] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAGERR_APER1'] = [w[0] for w in sexcat['MAGERR_APER']]\n",
    "        sexcat['MAGERR_APER3'] = [w[1] for w in sexcat['MAGERR_APER']]\n",
    "        sexcat['MAGERR_APER2'] = [w[2] for w in sexcat['MAGERR_APER']]\n",
    "        return sexcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "### Read from unaltered FLT frames with regridded whitelights###\n",
    "################################################################\n",
    "class read_sexcats():\n",
    "    def __init__(self):\n",
    "        phot_df = self.join(1)\n",
    "        self.phot_df = self.join(2, phot_df)\n",
    "        #phot_df = self.return_func(phot_df)\n",
    "        \n",
    "    def join(self, wfc, phot_df=None):\n",
    "        items = np.sort([w.split('_flt')[0] for w in glob('../SingleFrame_DetRegrid/WFC'+str(wfc)+'/*phot.fits')])\n",
    "        items = items\n",
    "        for iterator in range(len(items)):\n",
    "            item = items[iterator]\n",
    "            hdul = fits.open(glob(item+'*pamcorr_rate*')[0])\n",
    "            expstart = hdul[0].header['EXPSTART']\n",
    "            EXPTIME  = hdul[0].header['EXPTIME']\n",
    "            if EXPTIME < 31:\n",
    "                continue\n",
    "            filter_  = hdul[0].header['FILTER']\n",
    "            sexcat = Table.read(glob(item+'*phot*')[0], format=\"fits\", hdu='LDAC_OBJECTS')#.to_pandas()\n",
    "            sexcat = self.unpack_apers(sexcat)\n",
    "            sexcat.remove_columns(['MAG_APER', 'MAGERR_APER', 'FLUX_APER', 'FLUXERR_APER'])    \n",
    "            sexcat = sexcat.to_pandas()\n",
    "\n",
    "            sexcat = sexcat.rename(columns={'NUMBER':'SExID'})\n",
    "            sexcat = sexcat.rename(columns={'VECTOR_ASSOC':'AssocID'})\n",
    "            #sexcat['AssocID'] = 1\n",
    "            \n",
    "            sexcat['AssocID'] = sexcat['AssocID'].astype(int)\n",
    "            sexcat = sexcat[sexcat.AssocID!=0]\n",
    "            if wfc==2: \n",
    "                sexcat.SExID += phot_df[phot_df.WhichWFC==1].SExID.max()\n",
    "            #sexcat = sexcat.rename(columns={'VECTOR_ASSOC':'ID'})\n",
    "            #sexcat['ID'] = sexcat['ID'].astype(int)\n",
    "\n",
    "            sexcat['T_Start'] = expstart\n",
    "            sexcat['Exptime'] = EXPTIME\n",
    "            sexcat['Exp_Length'] = ('deep' if EXPTIME > 31 else 'short')\n",
    "            sexcat['Filter']     = filter_\n",
    "            sexcat['WhichWFC']   = wfc\n",
    "            sexcat = self.clean(sexcat)\n",
    "            #sexcat = sexcat.set_index('ID')\n",
    "            try:\n",
    "                phot_df = pd.concat((phot_df,sexcat), axis=0)\n",
    "            except:\n",
    "                phot_df = sexcat\n",
    "        return phot_df\n",
    "        \n",
    "    def return_func(self):\n",
    "        print('Done. Returning photometry dataframe')\n",
    "        return self.phot_df.set_index(['AssocID', 'Filter', 'T_Start']).sort_index()\n",
    "    \n",
    "    def clean(self, sexcat):\n",
    "        \"\"\"I take all rules from the HCV catalogue\"\"\"\n",
    "        sexcat = sexcat[(sexcat.MAG_APER2<80)&(sexcat.MAG_AUTO<80)]\n",
    "        sexcat = sexcat[sexcat.MAG_APER2<31.0]\n",
    "        sexcat = sexcat[sexcat.MAG_AUTO<35.0]\n",
    "        sexcat = sexcat[sexcat.FLAGS<=7]\n",
    "        sexcat = sexcat[sexcat.MAGERR_APER2<0.2]\n",
    "        return sexcat\n",
    "    \n",
    "    def unpack_apers(self, sexcat):\n",
    "        \"\"\"Unpacking the stacked lists\n",
    "           NOTES:\n",
    "           APER1 and APER2 refer to Whitmore et al 2016 (2.5 and 7.5 pixels diameter)\n",
    "           APER3 refers to our own aperture, which is 6 pixels in diameter\n",
    "           \"\"\"\n",
    "        sexcat['FLUX_APER1'] = [w[0] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUX_APER3'] = [w[1] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUX_APER2'] = [w[2] for w in sexcat['FLUX_APER']]\n",
    "        sexcat['FLUXERR_APER1'] = [w[0] for w in sexcat['FLUXERR_APER']]\n",
    "        sexcat['FLUXERR_APER3'] = [w[1] for w in sexcat['FLUXERR_APER']]\n",
    "        sexcat['FLUXERR_APER2'] = [w[2] for w in sexcat['FLUXERR_APER']]\n",
    "\n",
    "        sexcat['MAG_APER1'] = [w[0] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAG_APER3'] = [w[1] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAG_APER2'] = [w[2] for w in sexcat['MAG_APER']]\n",
    "        sexcat['MAGERR_APER1'] = [w[0] for w in sexcat['MAGERR_APER']]\n",
    "        sexcat['MAGERR_APER3'] = [w[1] for w in sexcat['MAGERR_APER']]\n",
    "        sexcat['MAGERR_APER2'] = [w[2] for w in sexcat['MAGERR_APER']]\n",
    "        return sexcat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCV_error_analysis():\n",
    "    def __init__(self, phot_df):\n",
    "        self.phot_df = phot_df\n",
    "        return\n",
    "\n",
    "    def get_CI(self,phot_df):\n",
    "        CI = phot_df['MAG_APER1'] - phot_df['MAG_APER2']\n",
    "        phot_df['CI'] = CI\n",
    "        return phot_df\n",
    "\n",
    "    def get_synthetic_err(self,phot_df):\n",
    "        \"\"\"Following the approach of the HCV paper\"\"\"\n",
    "        # I take the median, but note that there is always only ONE count, thus median = value\n",
    "        MagerrAper2  = phot_df.groupby(['AssocID', 'Filter','T_Start'])['MAGERR_APER2'].median()\n",
    "        MagerrAper2_timemedian = phot_df.groupby(['AssocID', 'Filter'])['MAGERR_APER2'].median()\n",
    "        MagDivision = (MagerrAper2 / MagerrAper2_timemedian)**2\n",
    "        \n",
    "        CI_timemedian = phot_df.CI.groupby(['AssocID', 'Filter']).median()\n",
    "        CIDivision    = (phot_df.CI / CI_timemedian)**2\n",
    "        \n",
    "        MagAper_MagAuto = (phot_df.MAG_APER2 - phot_df.MAG_AUTO)\n",
    "        MagAper_MagAuto_timemedian = MagAper_MagAuto.groupby(['AssocID', 'Filter']).median()\n",
    "        MagAper_MagAutoDivision = (MagAper_MagAuto/MagAper_MagAuto_timemedian)**2\n",
    "        \n",
    "        RATimemedian = phot_df.groupby(['AssocID', 'Filter', 'T_Start'])['ALPHA_J2000'].median()\n",
    "        DECTimemedian = phot_df.groupby(['AssocID', 'Filter', 'T_Start'])['DELTA_J2000'].median()\n",
    "\n",
    "        RAs = phot_df.groupby(['AssocID','Filter'])['ALPHA_J2000'].median()\n",
    "        DECs = phot_df.groupby(['AssocID', 'Filter'])['DELTA_J2000'].median()\n",
    "\n",
    "        DeltaRAs = np.power(RAs - RATimemedian,2)\n",
    "        DeltaDECs = np.power(DECs - DECTimemedian,2)\n",
    "\n",
    "        Dists = np.sqrt(DeltaRAs+DeltaDECs)\n",
    "        DistsTimemedian = Dists.groupby(['AssocID', 'Filter']).median()\n",
    "        DistsDivision   = (Dists/DistsTimemedian)**2\n",
    "        \n",
    "        SynError = np.sqrt(MagDivision + CIDivision + MagAper_MagAutoDivision + DistsDivision)\n",
    "        #ID = phot_df.groupby('SExID')['VECTOR_ASSOC'].median().astype(int)\n",
    "        #ID = ID.apply(lambda x: 1000000+x)\n",
    "        #ID[ID==1000000] = pd.Series(ID.index).apply(lambda x: 2000000+x).values\n",
    "        phot_df['SynError'] = SynError\n",
    "        \n",
    "        return phot_df\n",
    "    \n",
    "    def linfit(self,x,b):\n",
    "        return 1/np.inf*x+b\n",
    "    \n",
    "    def get_sigma_prime(self, phot_df):\n",
    "        StarIDs = phot_df.get_level_values(0).unique()\n",
    "        for StarID in StarIDs:\n",
    "            filters = phot_df.loc[StarIDs].index.get_level_values(0).unique()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_synthetic_err_deviation(self, phot_df):\n",
    "        SynErrorSTD = phot_df.groupby(['AssocID', 'Filter'])['SynError'].std() # Standard deviation of synthetic errors\n",
    "        SynErrorMed = phot_df.groupby(['AssocID', 'Filter'])['SynError'].median() # median of synthetic errors\n",
    "        SynErrorDev = (phot_df.SynError-SynErrorMed).abs()/SynErrorSTD # How many sigma is this measurement removed from the median\n",
    "        phot_df['SynErrorDevSig'] = SynErrorDev.values\n",
    "        phot_df['SynErrorMed'] = SynErrorMed\n",
    "        phot_df['SynErrorSig'] = phot_df.SynError / SynErrorMed\n",
    "        phot_df['High_sigma_syn'] = phot_df['SynErrorSig'] > 4\n",
    "        return phot_df\n",
    "    \n",
    "    \n",
    "    def robust_mean(self,mags, synerrs):\n",
    "        mags = mags.values\n",
    "        synerrs = synerrs.values\n",
    "        synerrs = synerrs[np.argsort(mags)]\n",
    "        mags = np.sort(mags)\n",
    "        if len(mags)>5:\n",
    "            to_drop = (len(mags)//6)\n",
    "            mags = mags[to_drop:-to_drop]\n",
    "            synerrs = synerrs[to_drop:-to_drop]\n",
    "        weighted_mean = np.nansum(1/synerrs**2 * mags) / np.nansum(1/synerrs**2)\n",
    "        return weighted_mean, np.sqrt(np.mean(np.power(mags-weighted_mean,2)))\n",
    "    \n",
    "    def get_mean_sigmaprime(self, phot_df):\n",
    "        phot_df = self.phot_df.copy()\n",
    "        \"\"\"This will take some time\"\"\"\n",
    "        StarIDs = phot_df.index.get_level_values(0).unique().values\n",
    "        phot_df['RobustMean'] = 0\n",
    "        phot_df['RobustSigma'] = 0\n",
    "        i=0\n",
    "        for StarID in StarIDs:\n",
    "            filters = phot_df.loc[StarID].index.get_level_values(0).unique()\n",
    "            for this_filter in filters:\n",
    "                sub_phot_df = phot_df.loc[StarID,this_filter]\n",
    "                Lightcurve_SynErrors = sub_phot_df.SynError\n",
    "                Lightcurve_mags = sub_phot_df.MAG_APER2\n",
    "                TrueMag, SigmaPrime = self.robust_mean(Lightcurve_mags, Lightcurve_SynErrors)\n",
    "                phot_df.loc[(StarID, this_filter,),'RobustMean'] = TrueMag\n",
    "                phot_df.loc[(StarID, this_filter,),'RobustSigma']= SigmaPrime\n",
    "        phot_df['SigmaPrimeDeviation'] = (phot_df['MAG_APER2'] - phot_df['RobustMean']).abs() / phot_df['RobustSigma']\n",
    "        phot_df['High_sigma_prime'] = phot_df['SigmaPrimeDeviation'] > 4\n",
    "        return phot_df\n",
    "    \n",
    "    def get_local_mzp_corr(self, phot_df):\n",
    "        phot_df['MagDiff'] = phot_df['MAG_APER2'] - phot_df['RobustMean']\n",
    "        nearest = nearest_neighbours(phot_df)\n",
    "        phot_df = phot_df[phot_df.Exp_Length == 'deep'].copy()\n",
    "        \n",
    "        IDs = phot_df.index.get_level_values(0).unique()\n",
    "        phot_df['MZPCorr']=0\n",
    "        for ID in IDs:\n",
    "            neightbours = nearest.loc[ID]\n",
    "            photometry = phot_df.loc[neightbours.values]\n",
    "            MagOffset = photometry.groupby(['Filter', 'T_Start'])['MagDiff'].median()\n",
    "            MagOffset = pd.DataFrame(MagOffset)\n",
    "            MagOffset.columns = ['MZPCorr2']\n",
    "            phot_df.loc[ID,'MZPCorr'] = pd.DataFrame(phot_df.loc[ID]).join(MagOffset)['MZPCorr2'].values\n",
    "        phot_df['MAG_APER2_ORIG'] = phot_df['MAG_APER2']\n",
    "        phot_df['MAG_APER2'] = phot_df['MAG_APER2'] - phot_df['MZPCorr']\n",
    "        return phot_df\n",
    "    \n",
    "    \n",
    "    def clean(self, MZPcorr=False):\n",
    "        phot_df = self.get_CI(self.phot_df)\n",
    "        phot_df = self.get_synthetic_err(phot_df)\n",
    "        phot_df = self.get_synthetic_err_deviation(phot_df)\n",
    "        phot_df = self.get_mean_sigmaprime(phot_df)\n",
    "        if MZPcorr:\n",
    "            phot_df = self.get_local_mzp_corr(phot_df)\n",
    "        phot_df = phot_df[phot_df.CI < 5]\n",
    "        phot_df = phot_df[(np.logical_not(phot_df.High_sigma_prime))*(np.logical_not(phot_df.High_sigma_syn))]\n",
    "        print('Done. Returning photometry dataframe including CI and synthetic errors and MZP correction')\n",
    "        return phot_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SExToCat(phot_df, cat):\n",
    "    SExCoordinates = phot_df.groupby('AssocID')['ALPHA_J2000', 'DELTA_J2000'].median()\n",
    "    CatCoordinates = all_stars[['RA', 'Dec']]\n",
    "    DeltaRA  = np.power(SExCoordinates.ALPHA_J2000.values - CatCoordinates.RA.values[:,np.newaxis],2, dtype=np.float32).T\n",
    "    DeltaDec = np.power(SExCoordinates.DELTA_J2000.values - CatCoordinates.Dec.values[:,np.newaxis],2, dtype=np.float32).T\n",
    "    Dists    = np.sqrt(DeltaRA + DeltaDec)\n",
    "    Dists[Dists>1e-4] = np.nan\n",
    "    del DeltaRA, DeltaDec\n",
    "    Dists     = pd.DataFrame(Dists, index = SExCoordinates.index, columns=all_stars.index)\n",
    "    Assoc_df  = pd.DataFrame({'RefCatID':Dists.idxmin(axis=1)})\n",
    "    return Assoc_df.dropna()\n",
    "def nearest_neighbours(phot_df, Nstars = 50):\n",
    "    catalogue = phot_df.groupby('AssocID')['ALPHA_J2000', 'DELTA_J2000'].median()\n",
    "    Nentries = len(catalogue)\n",
    "    \n",
    "    deltaRA  = np.memmap('deltaRA.temp' , dtype='float64', mode='w+', shape=(Nentries,Nentries))\n",
    "    deltaDEC = np.memmap('deltaDec.temp', dtype='float64', mode='w+', shape=(Nentries,Nentries))\n",
    "    \n",
    "    deltaRA[:]  = catalogue.ALPHA_J2000.values - catalogue.ALPHA_J2000.values[:,np.newaxis]\n",
    "    deltaDEC[:] = catalogue.DELTA_J2000.values - catalogue.DELTA_J2000.values[:,np.newaxis]\n",
    "    \n",
    "    deltaAngle = deltaRA**2 + deltaDEC**2\n",
    "    del deltaRA, deltaDEC\n",
    "    \n",
    "    nearest = catalogue.index.values[np.argsort(deltaAngle, axis=1)] # To correct for ID <-> argument\n",
    "    nearest = pd.DataFrame(nearest[:,1:Nstars+1], index=catalogue.index)\n",
    "    return nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis():\n",
    "    def __init__(self, phot_df):\n",
    "        self.ApplySelection(phot_df)\n",
    "        return\n",
    "\n",
    "    def ApplySelection(self, phot_df):\n",
    "        self.phot_df = phot_df[phot_df.SynErrorDevSig<=3]\n",
    "        self.phot_df = self.phot_df[self.phot_df.Exp_Length=='deep']\n",
    "    \n",
    "    def GetMADvalues(self):\n",
    "        phot_df          = self.phot_df\n",
    "        MedianMagTime    = phot_df.groupby(['AssocID', 'Filter', 'T_Start'])['MAG_APER2'].median()\n",
    "        MedianMagOverall = phot_df.groupby(['AssocID', 'Filter'])['RobustMean'].median()\n",
    "        MagOffset        = (MedianMagTime - MedianMagOverall).abs()\n",
    "        self.MAD         = MagOffset.groupby(['AssocID', 'Filter']).median()\n",
    "        return self.MAD\n",
    "    \n",
    "    def GetMedMags(self):\n",
    "        self.MedMag = self.phot_df.groupby(['AssocID', 'Filter'])['MAG_APER2'].median()\n",
    "        return self.MedMag\n",
    "    \n",
    "    def GetMADPlot(self, filter_=None):\n",
    "        self.GetMADvalues()\n",
    "        self.MAD.hist(bins=np.arange(0,1,0.002),cumulative=False, histtype='step', normed=False, linewidth=2)\n",
    "        plt.xlabel('MAD Value')\n",
    "        plt.ylabel('PDF')\n",
    "        plt.show()\n",
    "        \n",
    "        self.MAD.hist(bins=np.arange(0,1,0.002),cumulative=True, histtype='step', normed=True, linewidth=2)\n",
    "        plt.xlabel('MAD Value')\n",
    "        plt.ylabel('CDF')\n",
    "        plt.show()\n",
    "        \n",
    "        self.GetMedMags()\n",
    "        if filter_ !=None:\n",
    "            med_mags = self.MedMag[self.MedMag.index.get_level_values(1)==filter_]\n",
    "            mad_vals = self.MAD[self.MAD.index.get_level_values(1)==filter_]\n",
    "        else:\n",
    "            med_mags = self.MedMag#[self.MedMag.index.get_level_values(1)==filter_]\n",
    "            mad_vals = self.MAD#[self.MAD.index.get_level_values(1)==filter_]\n",
    "        plt.hist2d(med_mags, mad_vals, bins=(np.linspace(15,28,80), np.linspace(0,0.4,50)), cmap=plt.cm.jet)\n",
    "        plt.xlabel('Median magnitude')\n",
    "        plt.ylabel('MAG Value')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def DrawTrumpets(self,magcol = 'MAG_APER3', IDcol = 'AssocID'):\n",
    "        phot_df = self.phot_df\n",
    "        merrcol = magcol.replace('MAG', 'MERR')\n",
    "        # Trumpet plot\n",
    "        from matplotlib.colors import LogNorm\n",
    "        magnitudes = phot_df[magcol]\n",
    "        filters = magnitudes.index.get_level_values(1).unique()\n",
    "        plt.figure(figsize=(20,10))\n",
    "        num=0\n",
    "        for filter_ in np.sort(filters):\n",
    "            epochs  = magnitudes.loc[:,filter_,:].index.get_level_values(1).unique()\n",
    "            mags_t0 = pd.DataFrame(magnitudes.loc[:, filter_, epochs[0], :])\n",
    "            num+=1\n",
    "            plt.subplot('23'+str(num))\n",
    "            xs, ys = np.array([]), np.array([])\n",
    "            for i in range(len(epochs)-1):\n",
    "                mags_t1 = pd.DataFrame(magnitudes.loc[:, filter_, epochs[i+1], :])\n",
    "                join_mags = mags_t0.join(mags_t1, lsuffix = '_t0', rsuffix='_t1', how='inner')\n",
    "                join_mags['DeltaMag'] = join_mags[magcol+'_t1'] - join_mags[magcol+'_t0']\n",
    "                median_mags = magnitudes.loc[:, filter_, :].groupby([IDcol]).median()\n",
    "                join_mags = join_mags.join(median_mags)\n",
    "                x, y = join_mags[magcol].values, join_mags['DeltaMag'].values\n",
    "                x, y = x[np.isfinite(x)*np.isfinite(y)], y[np.isfinite(x)*np.isfinite(y)]\n",
    "                xs = np.hstack((xs,x))\n",
    "                ys = np.hstack((ys,y))\n",
    "            plt.hist2d(xs, ys, bins=(np.linspace(15,28,80), np.linspace(-3,3,150)), cmap='jet', cmin=15)\n",
    "            plt.title(filter_, pad=-15)\n",
    "            plt.ylabel('Delta Mag')\n",
    "            plt.xlabel('Median magnitude')\n",
    "            plt.ylim(-1,1)\n",
    "            plt.xlim(14,27)\n",
    "            if num in [1,4,7]:\n",
    "                plt.ylabel('Delta Mag')\n",
    "            else:\n",
    "                plt.yticks([])\n",
    "            if num in [4,5]:\n",
    "                plt.xlabel('Median magnitude')\n",
    "            else:\n",
    "                plt.xticks([])\n",
    "            plt.ylim(-1.5,1.5)\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig('trumpet_diagrams.png', dpi=500)\n",
    "        plt.show()\n",
    "\n",
    "    def MAG_pdf(self, magcol = 'MAG_APER2',fluxcol='FLUX_APER2', IDcol = 'AssocID'):\n",
    "        phot_df = self.phot_df\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        for name, group in phot_df[phot_df[fluxcol]>0].groupby('Filter')[magcol]:\n",
    "            group.hist(bins=np.arange(15,30,0.1), histtype='step', ax=ax, normed=True, label=name, linewidth=2)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Magnitude')\n",
    "        ax.set_ylabel('Normalized frequency')\n",
    "        ax.set_xlim(15,30)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        for name, group in phot_df[phot_df[fluxcol]>0].groupby('Filter')[magcol]:\n",
    "            group.hist(bins=np.arange(15,30,0.1),cumulative=True, histtype='step', ax=ax, normed=True, label=name, linewidth=2)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Magnitude')\n",
    "        ax.set_ylabel('Normalized frequency')\n",
    "        ax.set_xlim(15,30)\n",
    "        plt.show()\n",
    "    \n",
    "    def GetNumberOfMeasurements(self):\n",
    "        counts = self.phot_df['MAG_APER2'].groupby(['AssocID', 'Filter']).count()\n",
    "        return counts\n",
    "    \n",
    "    def GetTimeSeries(self, AssocID = None, Filter=None):\n",
    "        if not AssocID:\n",
    "            MinMeasurements = 10\n",
    "            WhichEntries    = self.GetNumberOfMeasurements()>MinMeasurements\n",
    "            WhichEntries    = WhichEntries[WhichEntries]\n",
    "            RandomRow       = np.random.randint(0,len(WhichEntries))\n",
    "            AssocID         = WhichEntries.index.get_level_values(0)[RandomRow]\n",
    "            Filter          = WhichEntries.index.get_level_values(1)[RandomRow]\n",
    "        JulianDates = self.phot_df.loc[AssocID, Filter].reset_index().T_Start\n",
    "        Magnitudes  = self.phot_df.loc[AssocID, Filter].MAG_APER2\n",
    "        Synth_err   = self.phot_df.loc[AssocID, Filter].SynErrorDevSig\n",
    "        MAG_err     = self.phot_df.loc[AssocID, Filter].MAGERR_APER2\n",
    "        \n",
    "        plt.errorbar(JulianDates, Magnitudes, yerr=Synth_err, linestyle='none', fmt='o', ecolor='black', capthick=2)\n",
    "        #plt.scatter(JulianDates, Magnitudes, marker='o', c='black')\n",
    "        \n",
    "\n",
    "    def median_mad_sigma(self):\n",
    "        mags, mads = self.GetMedMags(), self.GetMADvalues()  \n",
    "        mags = pd.DataFrame(mags)\n",
    "        mags.columns = ['MAG']\n",
    "        mads = pd.DataFrame(mads)\n",
    "        mads.columns = ['MAD']\n",
    "        # Drop first 0.5 mag and last 0.5 mag\n",
    "        lower_thres = pd.DataFrame(mags.groupby('Filter').min()+0.5)#FilterMags.min()+0.5\n",
    "        lower_thres.columns = ['LowerMagThresh']\n",
    "        upper_thres = pd.DataFrame(mags.groupby('Filter').max()-0.5)##FilterMags.max()-0.5\n",
    "        upper_thres.columns = ['UpperMagThresh']\n",
    "\n",
    "        mags = pd.merge(mags, lower_thres, left_index=True,left_on='Filter', right_index=True)#, right_on='Filter')\n",
    "        mags = pd.merge(mags, upper_thres, left_index=True,left_on='Filter', right_index=True)\n",
    "\n",
    "        mags = mags[(mags.MAG>mags.LowerMagThresh)*(mags.MAG<mags.UpperMagThresh)]\n",
    "        MagsMads = mags.copy()\n",
    "        MagsMads = MagsMads.join(mads)\n",
    "\n",
    "        MagsMads['MagBin'] = pd.cut(MagsMads['MAG'], bins=20)\n",
    "        MedMadBin = pd.DataFrame(MagsMads.groupby('MagBin')['MAD'].median())\n",
    "        MedMadBin.columns = ['MedMadBin']\n",
    "        MagsMads = pd.merge(MagsMads,MedMadBin, left_on='MagBin', right_index=True)\n",
    "\n",
    "        MagsMads['MADSigma'] = MagsMads['MAD'] / MagsMads['MedMadBin']\n",
    "        #MagsMads = MagsMads[MagsMads.MADSigma>6]\n",
    "        return MagsMads\n",
    "    \n",
    "    def potential_candidates(self):\n",
    "        MagsMads = self.median_mad_sigma()\n",
    "        PotCandidates = MagsMads['MAD'].unstack()\n",
    "        PotCandidates['NFilters'] = PotCandidates.count(axis=1)\n",
    "        return PotCandidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Code</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars = Table.read('../../../HST_Guido/30dor_all_newerr.UBVIHa.rot', format='ascii').to_pandas()\n",
    "all_stars.columns = 'ID;x;y;RA;Dec;u_1;eu_2;b_1;eb_2;v_1;ev_2;i_1;ei_2;ha_1;eha_2'.split(';')\n",
    "all_stars = all_stars.set_index('ID')\n",
    "#all_stars = all_stars[np.logical_not(((all_stars.ha_1<-10)+(all_stars.ha_1>50)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pms_stars = Table.read('../../../HST_Guido/30dorallpmsstars.txt', format='ascii').to_pandas()\n",
    "#pms_stars = pms_stars.set_index('NR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_df = read_sexcats().return_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_df = HCV_error_analysis(phot_df).clean(MZPcorr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = phot_df.groupby(['AssocID', 'Filter'])['MAG_APER2'].median()\n",
    "magnitudes = magnitudes.unstack()\n",
    "\n",
    "mads = Analyzer.GetMADvalues().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes['V_Ha'] = magnitudes['F555W'] - magnitudes['F656N']\n",
    "magnitudes['V_I'] = magnitudes['F555W'] - magnitudes['F814W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_df.groupby('Filter')['MAG_APER2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(magnitudes['V_I'], magnitudes['F555W'], s=1, marker='x', color='grey')\n",
    "plt.scatter(magnitudes['V_I'].loc[pot_cand], magnitudes['F555W'].loc[pot_cand], s=1, marker='x', color='red')\n",
    "#plt.scatter(magnitudes['V_I'].loc[pot_cand], magnitudes['V_Ha'].loc[pot_cand], s=1, marker='x', color='red')\n",
    "plt.ylim(30,10)\n",
    "plt.xlim(-0.5,3)\n",
    "plt.ylabel('V')\n",
    "plt.xlabel('V-I')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}