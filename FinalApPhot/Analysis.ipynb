{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badpixphotometry = 'NBadpix_all_exps.csv'\n",
    "photometryfile = 'APP_phot_all_exps.csv'\n",
    "\n",
    "N_CR_app_df = pd.read_csv(badpixphotometry)\n",
    "N_CR_app_df = N_CR_app_df.set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "N_CR_app_df['FracBadPix'] = N_CR_app_df['FLUX'] / N_CR_app_df['AREA']\n",
    "read_in = pd.read_csv(photometryfile)\n",
    "phot_df = read_in.copy().set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "# Join the photometry with the fraction of bad pixels\n",
    "phot_df_all_stars = phot_df.join(N_CR_app_df.FracBadPix, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badpixphotometry = 'NBadpix_all_exps_pmsstars.csv'\n",
    "photometryfile = 'APP_phot_all_exps_pmsstars.csv'\n",
    "\n",
    "N_CR_app_df = pd.read_csv(badpixphotometry)\n",
    "N_CR_app_df = N_CR_app_df.set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "N_CR_app_df['FracBadPix'] = N_CR_app_df['FLUX'] / N_CR_app_df['AREA']\n",
    "read_in = pd.read_csv(photometryfile)\n",
    "phot_df = read_in.copy().set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "# Join the photometry with the fraction of bad pixels\n",
    "phot_df_pms_stars = phot_df.join(N_CR_app_df.FracBadPix, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"photometryfile = 'APP_phot_all_exps_pmsstars_norecenter.csv'\n",
    "badpixphotometry = 'NBadpix_all_exps_pmsstars_norecenter.csv'\n",
    "N_CR_app_df = pd.read_csv(badpixphotometry)\n",
    "N_CR_app_df = N_CR_app_df.set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "N_CR_app_df['FracBadPix'] = N_CR_app_df['FLUX'] / N_CR_app_df['AREA']\n",
    "read_in = pd.read_csv(photometryfile)\n",
    "phot_df_pms_norecenter = read_in.copy().set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "# Join the photometry with the fraction of bad pixels\n",
    "phot_df_pms_stars_norecenter = phot_df.join(N_CR_app_df.FracBadPix, how='inner')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"photometryfile = 'APP_phot_all_exps_pmsstars_largeann.csv'\n",
    "\n",
    "#N_CR_app_df = pd.read_csv(badpixphotometry)\n",
    "#N_CR_app_df = N_CR_app_df.set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "#N_CR_app_df['FracBadPix'] = N_CR_app_df['FLUX'] / N_CR_app_df['AREA']\n",
    "read_in = pd.read_csv(photometryfile)\n",
    "phot_df_pms_stars_largeann = read_in.copy().set_index(['ID', 'Filter', 'T_Start', 'Exp_Length', 'DrizzleType'])\n",
    "# Join the photometry with the fraction of bad pixels\n",
    "#phot_df_pms_stars_largeann = phot_df.join(N_CR_app_df.FracBadPix, how='inner')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red giants\n",
    "red_giant_coords = ascii.read('../HST_Guido/redgiants_coords.txt')\n",
    "phot_df_redgiants = phot_df_all_stars.loc[red_giant_coords['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(phot_df, CRcorrect=True):\n",
    "    # We select only the magnitudes from the single drizzled frames\n",
    "    phot_df = phot_df[phot_df.index.get_level_values(4)=='SingleDrizzle']\n",
    "    # Only keep apertures with max 15% flagged pixels\n",
    "    if CRcorrect:\n",
    "        phot_df = phot_df[phot_df.FracBadPix < 0.6]\n",
    "        # Update the flux according to the number of bad pixels\n",
    "        phot_df['FluxCorr'] = phot_df['FLUX'] / (1-phot_df['FracBadPix'])\n",
    "        phot_df[phot_df['FluxCorr']!=phot_df['FLUX']]['CERROR'] = 'FixedBadPix'\n",
    "        # Update the magnitudes for the stars that did not have one\n",
    "        zmag  = {'F336W':23.46,'F438W':24.98,'F555W': 25.81, 'F814W': 24.67, 'F656N': 19.92}#[hst_filter]-0.1\n",
    "        phot_df_no_MAG = phot_df[phot_df.CERROR=='BadPixels']\n",
    "        phot_df['MAG'][phot_df.CERROR=='BadPixels'] = -2.5*np.log10(phot_df_no_MAG['FluxCorr']) + np.array([zmag[w] for w in phot_df_no_MAG.index.get_level_values(1).values])-0.1 +2.5*np.log10(phot_df_no_MAG['ITIME'])\n",
    "\n",
    "    phot_df = phot_df[phot_df.CERROR != 'BigShift']\n",
    "    \n",
    "    # Only select stars with V band magnitudes between 15 and 20\n",
    "    F555W      = phot_df[phot_df.index.get_level_values(1)=='F555W'].groupby(['ID'])['MAG'].median()\n",
    "    selection  = (F555W>15)*(F555W<28)\n",
    "    selection  = selection.index[selection].values\n",
    "    phot_df    = phot_df[[w in selection for w in phot_df.index.get_level_values(0)]]\n",
    "    #selection  = (F555W_mags < 18) * (F555W_mags > 15)\n",
    "    #phot_df    = phot_df[selection]\n",
    "    \n",
    "    # Take only values with no large shift\n",
    "    phot_df    = phot_df[phot_df.XSHIFT**2+phot_df.YSHIFT**2 < 4]\n",
    "    \n",
    "    # Normalize observation time \n",
    "    phot_df.loc[:,'Time'] = pd.to_numeric(phot_df.index.get_level_values(2))\n",
    "    phot_df.loc[:,'Time'] = phot_df['Time'] - phot_df['Time'].min()\n",
    "    \n",
    "    # Select only stars with limited std in magnitudes\n",
    "    groupby    = phot_df.groupby(['ID', 'Filter', 'Exp_Length', 'DrizzleType'])['MAG'].std()\n",
    "    groupby    = phot_df.groupby(['ID', 'Filter', 'Exp_Length', 'DrizzleType'])['MAG'].std()\n",
    "    groupby    = groupby.groupby('ID').median()<1.#groupby < 1.5\n",
    "    good_stars = groupby.index[groupby]\n",
    "    phot_df    = phot_df[[w in good_stars for w in phot_df.index.get_level_values(0)]]\n",
    "    #phot_df    = phot_df[[w in good_stars for w in phot_df.index.get_level_values(1)]]\n",
    "    #phot_df    = phot_df.droplevel([2,4]).loc[good_stars]\n",
    "    \n",
    "    # Select only stars with limited mag error\n",
    "    phot_df   = phot_df[phot_df['MERR']<0.2]\n",
    "    \n",
    "    # Select some stars with enough remaining measurements\n",
    "    groupby    = phot_df.reset_index(level=1).groupby('ID')['Filter'].nunique()>=3\n",
    "    good_stars = groupby.index[groupby]\n",
    "    phot_df    = phot_df[[w in good_stars for w in phot_df.index.get_level_values(0)]]\n",
    "\n",
    "    groupby    = (phot_df.groupby('ID')['MAG'].nunique()>25)\n",
    "    good_stars = groupby.index[groupby]\n",
    "    phot_df    = phot_df[[w in good_stars for w in phot_df.index.get_level_values(0)]]\n",
    "    \n",
    "    \n",
    "    # Select some stars with enough remaining measurements in specifically Ha \n",
    "    groupby = phot_df.groupby(['ID', 'Filter'])['MAG'].nunique()\n",
    "    groupby = groupby.reset_index()\n",
    "    groupby = groupby[groupby.Filter=='F656N']\n",
    "    good_stars = groupby[groupby['MAG']>=4].ID.values\n",
    "    phot_df    = phot_df[[w in good_stars for w in phot_df.index.get_level_values(0)]]\n",
    "    return phot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plots(phot_df, high_var=False):\n",
    "    # Select those with std(Ha)> std(broadband)\n",
    "    star_filter_std = phot_df.groupby(['ID', 'Filter'])['MAG'].std()\n",
    "    Ha_std   = star_filter_std[star_filter_std.index.get_level_values(1)=='F656N']\n",
    "    mean_std = star_filter_std.groupby('ID').mean()\n",
    "    high_Ha_var_stars = mean_std.index[Ha_std.droplevel(1) >= 1*mean_std].values\n",
    "    stellar_indices = phot_df.index.get_level_values(0).unique().values\n",
    "    high_Ha_var_stars\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(18,16))\n",
    "    gs1 = gridspec.GridSpec(3,3)\n",
    "    gs1.update(wspace=0, hspace=0) # set the spacing between axes. \n",
    "    Nstars_plot = 9\n",
    "    filterlist = phot_df.index.get_level_values(1).unique()[1:] #skip F336W\n",
    "    if high_var:\n",
    "        toplot = np.random.choice(high_Ha_var_stars, Nstars_plot, replace=False)\n",
    "    else:\n",
    "        toplot = np.random.choice(stellar_indices, Nstars_plot, replace=False)\n",
    "    for nstar, starID in enumerate(toplot):\n",
    "        for filter_iter, filter_ in enumerate(filterlist):\n",
    "            plt.subplot(gs1[nstar])\n",
    "            data = phot_df.loc[starID, filter_]\n",
    "            data = data[['MAG', 'MERR', 'Time']].sort_values(by='Time')\n",
    "            mags = data['MAG']\n",
    "            mags = mags - np.median(mags) + filter_iter\n",
    "            merr = data['MERR']\n",
    "            time = data['Time']\n",
    "            plt.plot(time,mags, linewidth=1.2, label=filter_)\n",
    "            plt.scatter(time,mags, c='red', s=5, label='')\n",
    "            F555W_mag = str(np.round(phot_df.loc[starID, 'F555W']['MAG'].median(), 1))\n",
    "            plt.errorbar(time, mags, yerr=merr, c='black', ls='none', label='')\n",
    "            plt.title('Star '+str(int(starID))+r'. $M_{G}=$'+F555W_mag, pad=-25, size=20)\n",
    "            plt.xlim(-1,8.3)\n",
    "\n",
    "            #plt.ylim(15.,18.5)\n",
    "            if nstar not in [0,3,6]:\n",
    "                plt.yticks([])\n",
    "            else:\n",
    "                plt.ylabel('Shifted magnitude', size=16)\n",
    "                plt.yticks(size=14)\n",
    "            if nstar not in [6,7,8]:\n",
    "                plt.xticks([])\n",
    "            else:\n",
    "                plt.xticks(size=16)\n",
    "                plt.xlabel(r'$\\Delta \\, T$ [days]',size=16)\n",
    "            plt.ylim(-0.3,len(filterlist)-0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(-0.5, -0.15),\n",
    "              fancybox=True, shadow=True, ncol=5, fontsize=16)\n",
    "    plt.suptitle(r'Stellar H$\\alpha$ brightness variability in 30-dor', y=1.03,fontsize=25)\n",
    "    plt.savefig('output.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    generate_plots(cleaned_df_pms, high_var=False)\n",
    "#except:\n",
    "cleaned_df_pms = prepare_df(phot_df_pms_stars, True)    \n",
    "generate_plots(cleaned_df_pms, high_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleaned_df_all = prepare_df(phot_df_all_stars, True)\n",
    "generate_plots(cleaned_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes[magnitudes.index.get_level_values(1)=='F814W']\n",
    "magnitudes.index.get_level_values(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redstars_df = prepare_df(phot_df_redgiants, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Trumpet plot\n",
    "magnitudes = redstars_df['MAG']\n",
    "magnitudes = magnitudes#[magnitudes.index.get_level_values(3)=='short']\n",
    "filters = magnitudes.index.get_level_values(1).unique()\n",
    "for filter_ in filters:\n",
    "    epochs  = magnitudes.loc[:,filter_,:].index.get_level_values(1).unique()\n",
    "    mags_t0 = pd.DataFrame(magnitudes.loc[:, filter_, epochs[0], :])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i in range(len(epochs)-1):\n",
    "        mags_t1 = pd.DataFrame(magnitudes.loc[:, filter_, epochs[i+1], :])\n",
    "        join_mags = mags_t0.join(mags_t1, lsuffix = '_t0', rsuffix='_t1', how='inner')\n",
    "        join_mags['DeltaMag'] = join_mags['MAG_t1'] - join_mags['MAG_t0']\n",
    "        median_mags = magnitudes.loc[:, filter_, :].groupby(['ID', 'Exp_Length', 'DrizzleType']).median()\n",
    "        join_mags = join_mags.join(median_mags)\n",
    "        plt.scatter(join_mags['MAG'], join_mags['DeltaMag'], s=1, c='grey')\n",
    "    plt.title('Delta Mag between adjecent epochs for '+str(filter_))\n",
    "    plt.ylabel('Delta Mag')\n",
    "    plt.xlabel('Median magnitude')\n",
    "    plt.ylim(-0.5,0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Trumpet plot\n",
    "from matplotlib.colors import LogNorm\n",
    "magnitudes = phot_df_all_stars['MAG']\n",
    "magnitudes = magnitudes[magnitudes.index.get_level_values(3)=='deep']\n",
    "filters = magnitudes.index.get_level_values(1).unique()\n",
    "for filter_ in filters:\n",
    "    epochs  = magnitudes.loc[:,filter_,:].index.get_level_values(1).unique()\n",
    "    mags_t0 = pd.DataFrame(magnitudes.loc[:, filter_, epochs[0], :])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    xs, ys = np.array([]), np.array([])\n",
    "    for i in range(len(epochs)-1):\n",
    "        mags_t1 = pd.DataFrame(magnitudes.loc[:, filter_, epochs[i+1], :])\n",
    "        join_mags = mags_t0.join(mags_t1, lsuffix = '_t0', rsuffix='_t1', how='inner')\n",
    "        join_mags['DeltaMag'] = join_mags['MAG_t1'] - join_mags['MAG_t0']\n",
    "        median_mags = magnitudes.loc[:, filter_, :].groupby(['ID', 'Exp_Length', 'DrizzleType']).median()\n",
    "        join_mags = join_mags.join(median_mags)\n",
    "        x, y = join_mags['MAG'].values, join_mags['DeltaMag'].values\n",
    "        x, y = x[np.isfinite(x)*np.isfinite(y)], y[np.isfinite(x)*np.isfinite(y)]\n",
    "        xs = np.hstack((xs,x))\n",
    "        ys = np.hstack((ys,y))\n",
    "    plt.hist2d(xs, ys, bins=700, cmap='jet', norm = LogNorm())\n",
    "    plt.title('Delta Mag between adjecent epochs for '+str(filter_))\n",
    "    plt.ylabel('Delta Mag')\n",
    "    plt.xlabel('Median magnitude')\n",
    "    plt.ylim(-0.5,0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}